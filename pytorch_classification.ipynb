{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbC865h7fHks",
        "outputId": "9c429192-2242-4e03-cefd-3b5da96203fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device is: cpu\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "\n",
        "--- virtualenv = torch_env ---\n",
        "\n",
        "We are trying to create a multiclass classification model for hand gesture\n",
        "detection. there are altogether 8 gestures labelled from 0-7 which are used to control \n",
        "the  tello drone ultimately.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "#setting up device agnostic code\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"device is: {device}\")\n",
        "\n",
        "# pre-processed landmarks self-made dataset\n",
        "# url='https://raw.githubusercontent.com/Bikash9841/gestureD/main/keypoint.csv'\n",
        "\n",
        "\n",
        "# this is from github dataset but for 8 gestures\n",
        "url='https://media.githubusercontent.com/media/kinivi/tello-gesture-control/main/model/keypoint_classifier/keypoint.csv'\n",
        "\n",
        "df=pd.read_csv(url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of dataframe: (6189, 43)\n",
            "features: (6189, 42) labels: (6189,)\n",
            "[1594 1663 1510  672  164  257  139  190]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "df=shuffle(df,random_state=42)\n",
        "print(f\"shape of dataframe: {df.shape}\")\n",
        "\n",
        "'''\n",
        "# extracting features from self-made dataset\n",
        "X=df.iloc[:,:42].values\n",
        "y=df.iloc[:,42].values\n",
        "'''\n",
        "\n",
        "# for github's 8 dataset\n",
        "req_df=df.iloc[:,1:]\n",
        "X=req_df.values\n",
        "y=df.iloc[:,0].values\n",
        "\n",
        "\n",
        "\n",
        "print(f\"features: {X.shape} labels: {y.shape}\")\n",
        "\n",
        "# turning data into tensors\n",
        "X=torch.from_numpy(X).type(torch.float).to(device)\n",
        "y=torch.from_numpy(y).type(torch.LongTensor).to(device)\n",
        "\n",
        "\n",
        "# visualizing dataset\n",
        "\n",
        "# Count the number of samples for each label\n",
        "label_counts = np.bincount(y)\n",
        "print(label_counts)\n",
        "\n",
        "# Plotting the bar plot\n",
        "plt.bar(range(len(label_counts)), label_counts, tick_label=range(len(label_counts)))\n",
        "plt.title('Number of Samples for Each Label')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4Uu3aHWtlk2",
        "outputId": "c6484200-30c9-43cb-a557-c38299bd8063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set: torch.Size([4951, 42]), test set: torch.Size([1238, 42]) ,train/test labels: torch.Size([4951]),torch.Size([1238])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GestureModel(\n",
              "  (linear_layer_stack): Sequential(\n",
              "    (0): Linear(in_features=42, out_features=16, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=16, out_features=16, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=16, out_features=16, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Linear(in_features=16, out_features=8, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# splitting dataset into train and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42)\n",
        "\n",
        "print(f\"train set: {X_train.shape}, test set: {X_test.shape} ,train/test labels: {y_train.shape},{y_test.shape}\")\n",
        "\n",
        "\n",
        "class GestureModel(nn.Module):\n",
        "  def __init__(self,input_features,output_features,hidden_units=16):\n",
        "\n",
        "    super().__init__()\n",
        "    self.linear_layer_stack = nn.Sequential(\n",
        "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_features), # how many classes are there?\n",
        "        )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.linear_layer_stack(x)\n",
        "\n",
        "# create a instance of model and send it to the target device\n",
        "model_1=GestureModel(42,8).to(device)\n",
        "\n",
        "model_1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4pd7HEFzkwV",
        "outputId": "7985cd36-5442-488b-f613-878e07cfe6d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0668, -0.0312, -0.1862,  0.0319,  0.1422,  0.1685, -0.1980,  0.1607],\n",
              "        [ 0.0630, -0.0297, -0.1813,  0.0318,  0.1436,  0.1705, -0.1987,  0.1634],\n",
              "        [ 0.0697, -0.0385, -0.1919,  0.0346,  0.1495,  0.1734, -0.1931,  0.1676],\n",
              "        [ 0.0691, -0.0277, -0.1857,  0.0253,  0.1370,  0.1671, -0.1948,  0.1639],\n",
              "        [ 0.0663, -0.0265, -0.1833,  0.0297,  0.1380,  0.1693, -0.1988,  0.1638]],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_1.parameters(), \n",
        "                            lr=0.1)\n",
        "\n",
        "# Perform a single forward pass on the data (we'll need to put it to the target device for it to work)\n",
        "model_1(X_train)[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95tYc5K2BELw",
        "outputId": "477246b5-9baf-45de-e2d1-027cd74989eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0629, -0.0289, -0.1828,  ...,  0.1672, -0.1992,  0.1614],\n",
            "        [ 0.0708, -0.0331, -0.1910,  ...,  0.1696, -0.1951,  0.1630],\n",
            "        [ 0.0669, -0.0274, -0.1842,  ...,  0.1690, -0.1972,  0.1640],\n",
            "        ...,\n",
            "        [ 0.0520, -0.0326, -0.1748,  ...,  0.1687, -0.2010,  0.1609],\n",
            "        [ 0.0677, -0.0332, -0.1873,  ...,  0.1730, -0.1958,  0.1685],\n",
            "        [ 0.0509, -0.0307, -0.1711,  ...,  0.1714, -0.2018,  0.1604]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([0.1294, 0.1181, 0.1012, 0.1253, 0.1400, 0.1436, 0.0996, 0.1428],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "tensor(5)\n"
          ]
        }
      ],
      "source": [
        "# Make prediction logits with model without actually training just to see the working of softmax \n",
        "y_logits = model_1(X_test)\n",
        "\n",
        "print(y_logits)\n",
        "# Perform softmax calculation on logits across dimension 1 to get prediction probabilities\n",
        "y_pred_probs = torch.softmax(y_logits, dim=1) \n",
        "\n",
        "# print(y_logits[:5])\n",
        "# print(y_pred_probs[:5])\n",
        "\n",
        "\n",
        "# Which class does the model think is *most* likely at the index 0 sample?\n",
        "print(y_pred_probs[0])\n",
        "\n",
        "# just select the largest probabilities among 8 classses of 0th index.\n",
        "print(torch.argmax(y_pred_probs[0]))\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8tQT3M9KCXGF"
      },
      "source": [
        "-----------------------------------------LETS TRAIN OUR MODEL NOW.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7Ao7vDoUH1VY"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy (a classification metric)\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
        "    acc = (correct / len(y_pred)) * 100 \n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFO1SAMtpEAu",
        "outputId": "1f8c373c-802a-4a9b-b089-7a8a65df74cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Loss: 2.13109, Acc: 4.38% | Test Loss: 2.11126, Test Acc: 3.23%\n",
            "Epoch: 10 | Loss: 1.98494, Acc: 26.06% | Test Loss: 1.97139, Test Acc: 26.58%\n",
            "Epoch: 20 | Loss: 1.87586, Acc: 26.94% | Test Loss: 1.86681, Test Acc: 26.58%\n",
            "Epoch: 30 | Loss: 1.79804, Acc: 26.94% | Test Loss: 1.79303, Test Acc: 26.58%\n",
            "Epoch: 40 | Loss: 1.75039, Acc: 26.94% | Test Loss: 1.74828, Test Acc: 26.58%\n",
            "Epoch: 50 | Loss: 1.72568, Acc: 26.94% | Test Loss: 1.72472, Test Acc: 26.58%\n",
            "Epoch: 60 | Loss: 1.71344, Acc: 26.94% | Test Loss: 1.71257, Test Acc: 26.58%\n",
            "Epoch: 70 | Loss: 1.70703, Acc: 26.94% | Test Loss: 1.70583, Test Acc: 26.58%\n",
            "Epoch: 80 | Loss: 1.70307, Acc: 26.94% | Test Loss: 1.70157, Test Acc: 26.58%\n",
            "Epoch: 90 | Loss: 1.70013, Acc: 26.94% | Test Loss: 1.69843, Test Acc: 26.58%\n",
            "Epoch: 100 | Loss: 1.69761, Acc: 26.94% | Test Loss: 1.69582, Test Acc: 26.58%\n",
            "Epoch: 110 | Loss: 1.69519, Acc: 26.94% | Test Loss: 1.69336, Test Acc: 26.58%\n",
            "Epoch: 120 | Loss: 1.69264, Acc: 26.94% | Test Loss: 1.69082, Test Acc: 26.58%\n",
            "Epoch: 130 | Loss: 1.68980, Acc: 26.94% | Test Loss: 1.68802, Test Acc: 26.58%\n",
            "Epoch: 140 | Loss: 1.68652, Acc: 26.94% | Test Loss: 1.68479, Test Acc: 26.58%\n",
            "Epoch: 150 | Loss: 1.68266, Acc: 27.07% | Test Loss: 1.68098, Test Acc: 26.58%\n",
            "Epoch: 160 | Loss: 1.67801, Acc: 27.11% | Test Loss: 1.67638, Test Acc: 26.74%\n",
            "Epoch: 170 | Loss: 1.67239, Acc: 27.43% | Test Loss: 1.67078, Test Acc: 27.06%\n",
            "Epoch: 180 | Loss: 1.66538, Acc: 28.58% | Test Loss: 1.66374, Test Acc: 28.92%\n",
            "Epoch: 190 | Loss: 1.65645, Acc: 28.78% | Test Loss: 1.65472, Test Acc: 28.92%\n",
            "Epoch: 200 | Loss: 1.64506, Acc: 29.04% | Test Loss: 1.64315, Test Acc: 29.32%\n",
            "Epoch: 210 | Loss: 1.63089, Acc: 29.37% | Test Loss: 1.62882, Test Acc: 30.29%\n",
            "Epoch: 220 | Loss: 1.61378, Acc: 30.22% | Test Loss: 1.61134, Test Acc: 31.18%\n",
            "Epoch: 230 | Loss: 1.59264, Acc: 32.88% | Test Loss: 1.58951, Test Acc: 34.65%\n",
            "Epoch: 240 | Loss: 1.56690, Acc: 36.46% | Test Loss: 1.56275, Test Acc: 39.34%\n",
            "Epoch: 250 | Loss: 1.53595, Acc: 39.31% | Test Loss: 1.53062, Test Acc: 42.33%\n",
            "Epoch: 260 | Loss: 1.50105, Acc: 41.71% | Test Loss: 1.49478, Test Acc: 43.86%\n",
            "Epoch: 270 | Loss: 1.46327, Acc: 44.90% | Test Loss: 1.45618, Test Acc: 46.20%\n",
            "Epoch: 280 | Loss: 1.42047, Acc: 50.39% | Test Loss: 1.41238, Test Acc: 52.26%\n",
            "Epoch: 290 | Loss: 1.37189, Acc: 53.91% | Test Loss: 1.36333, Test Acc: 55.09%\n",
            "Epoch: 300 | Loss: 1.32160, Acc: 55.46% | Test Loss: 1.31290, Test Acc: 56.54%\n",
            "Epoch: 310 | Loss: 1.27118, Acc: 57.00% | Test Loss: 1.26252, Test Acc: 57.92%\n",
            "Epoch: 320 | Loss: 1.21996, Acc: 63.74% | Test Loss: 1.21106, Test Acc: 64.05%\n",
            "Epoch: 330 | Loss: 1.17918, Acc: 66.17% | Test Loss: 1.18953, Test Acc: 56.95%\n",
            "Epoch: 340 | Loss: 1.25061, Acc: 48.68% | Test Loss: 1.22863, Test Acc: 52.10%\n",
            "Epoch: 350 | Loss: 1.19202, Acc: 53.02% | Test Loss: 1.20665, Test Acc: 53.15%\n",
            "Epoch: 360 | Loss: 1.13870, Acc: 57.46% | Test Loss: 1.12005, Test Acc: 61.47%\n",
            "Epoch: 370 | Loss: 1.25508, Acc: 43.77% | Test Loss: 1.30287, Test Acc: 47.01%\n",
            "Epoch: 380 | Loss: 1.01219, Acc: 66.39% | Test Loss: 1.00332, Test Acc: 69.31%\n",
            "Epoch: 390 | Loss: 1.48583, Acc: 35.67% | Test Loss: 1.18376, Test Acc: 51.78%\n",
            "Epoch: 400 | Loss: 0.93432, Acc: 68.71% | Test Loss: 0.94063, Test Acc: 70.52%\n",
            "Epoch: 410 | Loss: 0.98708, Acc: 61.30% | Test Loss: 0.94225, Test Acc: 70.03%\n",
            "Epoch: 420 | Loss: 0.97021, Acc: 60.67% | Test Loss: 1.09348, Test Acc: 54.20%\n",
            "Epoch: 430 | Loss: 0.83978, Acc: 73.34% | Test Loss: 0.83605, Test Acc: 75.04%\n",
            "Epoch: 440 | Loss: 1.19633, Acc: 50.45% | Test Loss: 1.41467, Test Acc: 40.39%\n",
            "Epoch: 450 | Loss: 0.76635, Acc: 76.65% | Test Loss: 0.76817, Test Acc: 76.41%\n",
            "Epoch: 460 | Loss: 1.37555, Acc: 45.16% | Test Loss: 1.43792, Test Acc: 39.01%\n",
            "Epoch: 470 | Loss: 0.70724, Acc: 78.21% | Test Loss: 0.71100, Test Acc: 77.30%\n",
            "Epoch: 480 | Loss: 0.77280, Acc: 70.35% | Test Loss: 0.98962, Test Acc: 62.60%\n",
            "Epoch: 490 | Loss: 0.66394, Acc: 79.16% | Test Loss: 0.66730, Test Acc: 78.59%\n",
            "Epoch: 500 | Loss: 0.60400, Acc: 81.60% | Test Loss: 0.61046, Test Acc: 80.69%\n",
            "Epoch: 510 | Loss: 0.84086, Acc: 67.56% | Test Loss: 0.68583, Test Acc: 78.68%\n",
            "Epoch: 520 | Loss: 0.56767, Acc: 82.19% | Test Loss: 0.57195, Test Acc: 81.66%\n",
            "Epoch: 530 | Loss: 0.52834, Acc: 83.70% | Test Loss: 0.54142, Test Acc: 83.36%\n",
            "Epoch: 540 | Loss: 0.69643, Acc: 79.78% | Test Loss: 0.65055, Test Acc: 75.44%\n",
            "Epoch: 550 | Loss: 0.50186, Acc: 84.73% | Test Loss: 0.50258, Test Acc: 84.17%\n",
            "Epoch: 560 | Loss: 0.68364, Acc: 75.32% | Test Loss: 0.77072, Test Acc: 72.05%\n",
            "Epoch: 570 | Loss: 0.66360, Acc: 78.43% | Test Loss: 0.52182, Test Acc: 83.76%\n",
            "Epoch: 580 | Loss: 0.43429, Acc: 88.69% | Test Loss: 0.43247, Test Acc: 87.80%\n",
            "Epoch: 590 | Loss: 1.14967, Acc: 59.73% | Test Loss: 0.90231, Test Acc: 65.75%\n",
            "Epoch: 600 | Loss: 0.41334, Acc: 89.64% | Test Loss: 0.40923, Test Acc: 89.26%\n",
            "Epoch: 610 | Loss: 0.37443, Acc: 90.73% | Test Loss: 0.37210, Test Acc: 90.39%\n",
            "Epoch: 620 | Loss: 0.40211, Acc: 88.65% | Test Loss: 0.46688, Test Acc: 85.70%\n",
            "Epoch: 630 | Loss: 1.06135, Acc: 66.73% | Test Loss: 1.80600, Test Acc: 60.02%\n",
            "Epoch: 640 | Loss: 0.35713, Acc: 92.22% | Test Loss: 0.35180, Test Acc: 91.76%\n",
            "Epoch: 650 | Loss: 0.32255, Acc: 93.07% | Test Loss: 0.31889, Test Acc: 92.97%\n",
            "Epoch: 660 | Loss: 0.29921, Acc: 93.76% | Test Loss: 0.29618, Test Acc: 93.38%\n",
            "Epoch: 670 | Loss: 0.31588, Acc: 94.22% | Test Loss: 0.34040, Test Acc: 90.79%\n",
            "Epoch: 680 | Loss: 1.13062, Acc: 64.92% | Test Loss: 0.80446, Test Acc: 76.41%\n",
            "Epoch: 690 | Loss: 0.31482, Acc: 92.87% | Test Loss: 0.30778, Test Acc: 92.73%\n",
            "Epoch: 700 | Loss: 0.28157, Acc: 93.98% | Test Loss: 0.27770, Test Acc: 93.62%\n",
            "Epoch: 710 | Loss: 0.26085, Acc: 94.67% | Test Loss: 0.25829, Test Acc: 94.51%\n",
            "Epoch: 720 | Loss: 0.24596, Acc: 94.97% | Test Loss: 0.24375, Test Acc: 94.75%\n",
            "Epoch: 730 | Loss: 0.23480, Acc: 95.25% | Test Loss: 0.23320, Test Acc: 94.43%\n",
            "Epoch: 740 | Loss: 0.29010, Acc: 93.76% | Test Loss: 0.33960, Test Acc: 90.15%\n",
            "Epoch: 750 | Loss: 0.40408, Acc: 87.54% | Test Loss: 0.32721, Test Acc: 92.00%\n",
            "Epoch: 760 | Loss: 0.26771, Acc: 93.74% | Test Loss: 0.26087, Test Acc: 93.21%\n",
            "Epoch: 770 | Loss: 0.23970, Acc: 94.77% | Test Loss: 0.23640, Test Acc: 94.26%\n",
            "Epoch: 780 | Loss: 0.22183, Acc: 95.48% | Test Loss: 0.22077, Test Acc: 94.75%\n",
            "Epoch: 790 | Loss: 0.20975, Acc: 95.66% | Test Loss: 0.20932, Test Acc: 94.99%\n",
            "Epoch: 800 | Loss: 0.20068, Acc: 95.80% | Test Loss: 0.20068, Test Acc: 95.23%\n",
            "Epoch: 810 | Loss: 0.19307, Acc: 95.92% | Test Loss: 0.19366, Test Acc: 95.56%\n",
            "Epoch: 820 | Loss: 0.18697, Acc: 95.92% | Test Loss: 0.18833, Test Acc: 95.88%\n",
            "Epoch: 830 | Loss: 0.18921, Acc: 95.50% | Test Loss: 0.19317, Test Acc: 96.20%\n",
            "Epoch: 840 | Loss: 0.26586, Acc: 92.79% | Test Loss: 0.29728, Test Acc: 92.65%\n",
            "Epoch: 850 | Loss: 0.30450, Acc: 93.09% | Test Loss: 0.26314, Test Acc: 92.89%\n",
            "Epoch: 860 | Loss: 0.21409, Acc: 94.24% | Test Loss: 0.20958, Test Acc: 94.02%\n",
            "Epoch: 870 | Loss: 0.19320, Acc: 95.66% | Test Loss: 0.19221, Test Acc: 95.07%\n",
            "Epoch: 880 | Loss: 0.18117, Acc: 96.02% | Test Loss: 0.18240, Test Acc: 95.32%\n",
            "Epoch: 890 | Loss: 0.17281, Acc: 96.26% | Test Loss: 0.17550, Test Acc: 95.40%\n",
            "Epoch: 900 | Loss: 0.16614, Acc: 96.38% | Test Loss: 0.16961, Test Acc: 95.64%\n",
            "Epoch: 910 | Loss: 0.16056, Acc: 96.55% | Test Loss: 0.16432, Test Acc: 95.64%\n",
            "Epoch: 920 | Loss: 0.15578, Acc: 96.65% | Test Loss: 0.15976, Test Acc: 95.80%\n",
            "Epoch: 930 | Loss: 0.15148, Acc: 96.75% | Test Loss: 0.15558, Test Acc: 95.96%\n",
            "Epoch: 940 | Loss: 0.14764, Acc: 96.85% | Test Loss: 0.15181, Test Acc: 96.04%\n",
            "Epoch: 950 | Loss: 0.14409, Acc: 96.95% | Test Loss: 0.14827, Test Acc: 96.20%\n",
            "Epoch: 960 | Loss: 0.14062, Acc: 97.03% | Test Loss: 0.14478, Test Acc: 96.28%\n",
            "Epoch: 970 | Loss: 0.13739, Acc: 97.03% | Test Loss: 0.14165, Test Acc: 96.45%\n",
            "Epoch: 980 | Loss: 0.13436, Acc: 97.17% | Test Loss: 0.13878, Test Acc: 96.45%\n",
            "Epoch: 990 | Loss: 0.13142, Acc: 97.23% | Test Loss: 0.13613, Test Acc: 96.45%\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Set number of epochs\n",
        "epochs = 1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    ### Training\n",
        "    model_1.train()\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_logits = model_1(X_train) # model outputs raw logits \n",
        "    y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1) # go from logits -> prediction probabilities -> prediction labels\n",
        "    # print(y_logits)\n",
        "    # 2. Calculate loss and accuracy\n",
        "    loss = loss_fn(y_logits, y_train) \n",
        "    acc = accuracy_fn(y_true=y_train,\n",
        "                      y_pred=y_pred)\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backwards\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "    model_1.eval()\n",
        "    with torch.inference_mode():\n",
        "      # 1. Forward pass\n",
        "      test_logits = model_1(X_test)\n",
        "      test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
        "      # 2. Calculate test loss and accuracy\n",
        "      test_loss = loss_fn(test_logits, y_test)\n",
        "      test_acc = accuracy_fn(y_true=y_test,\n",
        "                             y_pred=test_pred)\n",
        "\n",
        "    # Print out what's happening\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWZYh1TqIsUW",
        "outputId": "fca07fbb-8327-4879-da84-ff93f9e9194b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1 score: 0.951414381556589\n",
            "Predictions: tensor([7, 0, 0, 2, 1, 0, 1, 1, 2, 1])\n",
            "Labels: tensor([7, 0, 0, 2, 1, 0, 1, 1, 2, 1])\n",
            "Test accuracy: 96.52665589660742%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Make predictions\n",
        "model_1.eval()\n",
        "with torch.inference_mode():\n",
        "    y_logits = model_1(X_test)\n",
        "\n",
        "# View the first 10 predictions\n",
        "y_logits[10:20]\n",
        "\n",
        "\n",
        "# Turn predicted logits in prediction probabilities\n",
        "y_pred_probs = torch.softmax(y_logits, dim=1)\n",
        "\n",
        "# Turn prediction probabilities into prediction labels\n",
        "y_preds = y_pred_probs.argmax(dim=1)\n",
        "\n",
        "# f1 = F1Score(task=\"multiclass\", num_classes=8)\n",
        "\n",
        "print(f\"f1 score: {f1_score(y_test,y_preds,average='macro')}\")\n",
        "\n",
        "\n",
        "# Compare first 10 model preds and test labels\n",
        "print(f\"Predictions: {y_preds[10:20]}\\nLabels: {y_test[10:20]}\")\n",
        "print(f\"Test accuracy: {accuracy_fn(y_true=y_test, y_pred=y_preds)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SG4-qcqJPbZ",
        "outputId": "188970f1-4471-4593-cf56-328928b555b2"
      },
      "outputs": [],
      "source": [
        "# Saving the model\n",
        "\n",
        "# saving and loading a trained model\n",
        "# from pathlib import Path\n",
        "\n",
        "# # 1. create models directory\n",
        "# MODEL_PATH=Path(\"models\")\n",
        "# MODEL_PATH.mkdir(parents=True,exist_ok=True)\n",
        "\n",
        "# 2. create model save path\n",
        "# MODEL_NAME=\"01_gesture_detection.pth\"\n",
        "# MODEL_SAVE_PATH=MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# # 3. save the model state dict\n",
        "\n",
        "# print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "# torch.save(obj=model_1.state_dict(),f=MODEL_SAVE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oWX3Y4LwJmv2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# -------------------------- NEXT TIME YOU CAN START FROM HERE BY LOADING THE MODEL DIRECTLY-----------------\n",
        "\n",
        "\n",
        "# load a pytorch model\n",
        "\n",
        "# create a new instace of linear regression model V2\n",
        "\n",
        "# loaded_GestureModel_1=GestureModel(42,8)\n",
        "\n",
        "# # load the saved model state_dict\n",
        "# loaded_GestureModel_1.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "\n",
        "# # put the loaded model to device\n",
        "# loaded_GestureModel_1.to(device)\n",
        "\n",
        "def detectGes(X, orgX, orgY):\n",
        "  # print(X.shape)\n",
        "  # processing data to make it like the data we train on\n",
        "  # print(X)\n",
        "\n",
        "  for id, cood in enumerate(X[0]):\n",
        "    if (id % 2 == 0):\n",
        "      # X[0][id]=torch.round((cood-orgX),decimals=3)\n",
        "      X[0][id] = (cood-orgX)\n",
        "    else:\n",
        "      # X[0][id]=torch.round((cood-orgY),decimals=3)\n",
        "      X[0][id] = (cood-orgY)\n",
        "\n",
        "  # print(X)\n",
        "\n",
        "  maxVal=abs(X[0][0])\n",
        "  for val in X[0]:\n",
        "    if(abs(val)>abs(maxVal)):\n",
        "      maxVal=val\n",
        "  \n",
        "  # print(maxVal)\n",
        "  \n",
        "  # for id,cood in enumerate(X[0]):\n",
        "  #   X[0][id]=torch.round((X[0][id]/abs(maxVal)),decimals=3)\n",
        "  \n",
        "  # X[0]=torch.round(X[0]/abs(maxVal),decimals=3)\n",
        "  X[0]=X[0]/abs(maxVal)\n",
        "  # print(maxVal)\n",
        "  # print(X)\n",
        "\n",
        "  return torch.softmax(model_1(X), dim=1).argmax(dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def preprocess(data):\n",
        "    # first make all landmarks coordinate relative to zero\n",
        "    # then normalize it to the maximum value\n",
        "    # print(data)\n",
        "    for i in range(len(data)):\n",
        "        orgX = data[i][0]\n",
        "        orgY = data[i][1]\n",
        "        for id, cood in enumerate(data[i]):\n",
        "            if id < 42:\n",
        "                if (id % 2 == 0):\n",
        "                    data[i][id] = round((cood-orgX), 3)\n",
        "                else:\n",
        "                    data[i][id] = round((cood-orgY), 3)\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        # print(data)\n",
        "        maxVal = abs(data[i][0])\n",
        "        # maxVal = abs(data[i][1])\n",
        "        # print(f\"inital: {maxVal}\")\n",
        "        for idd, val in enumerate(data[i]):\n",
        "            if idd < 42:\n",
        "                if (abs(val) > abs(maxVal)):\n",
        "                    maxVal = val\n",
        "            else:\n",
        "                break\n",
        "        # print(f\"final: {maxVal}\")\n",
        "        for id, cood in enumerate(data[i]):\n",
        "            if id < 42:\n",
        "                data[i][id] = round((data[i][id]/abs(maxVal)), 3)\n",
        "    \n",
        "    # print(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "InmU3OIMKP1q",
        "outputId": "4b73aaff-61a9-4221-bd86-ea1d52c2ece2"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import time\n",
        "from djitellopy import Tello\n",
        "from threading import Thread, Lock, Event\n",
        "\n",
        "left_right_vel=0\n",
        "forward_backward_vel=0\n",
        "up_down_vel=0\n",
        "land=False\n",
        "gesture_event=Event()\n",
        "\n",
        "\n",
        "# drone=Tello()\n",
        "# drone.connect()\n",
        "# print(drone.get_battery())\n",
        "# start streaming video from\n",
        "# drone.streamon()\n",
        "\n",
        "'''\n",
        "In some cases, when working with tensors, the values of the tensor are not actually stored in memory, but are calculated on-the-fly as needed. \n",
        "When you assign a variable to an element of a tensor, you may be getting a reference to a calculation rather than a value stored in memory. \n",
        "As a result, changes to the tensor may affect the value of the variable even if the variable was not explicitly reassigned.\n",
        "\n",
        "One way to avoid this behavior is to create a copy of the tensor using the clone() method before assigning it to a variable.\n",
        "'''\n",
        "\n",
        "lock=Lock()\n",
        "# a thread-function to control the drone movement\n",
        "def show_movement():\n",
        "\n",
        "    count=1\n",
        "    if(count==1):\n",
        "        # drone.takeoff()\n",
        "        time.sleep(1)\n",
        "        # drone.move(\"up\",20)\n",
        "\n",
        "    while(True):\n",
        "        # wait for the gesture update\n",
        "        gesture_event.wait()  \n",
        "        with lock:\n",
        "\n",
        "            landT=land\n",
        "            lrv=left_right_vel\n",
        "            fbv=forward_backward_vel\n",
        "            udv=up_down_vel\n",
        "\n",
        "            if(landT==True and lrv==0 and fbv==0 and udv==0):\n",
        "                # drone.land()\n",
        "                time.sleep(1)\n",
        "                break\n",
        "            else:    \n",
        "                # drone.send_rc_control(lrv,fbv,udv,0)\n",
        "                pass\n",
        "\n",
        "        gesture_event.clear()\n",
        "\n",
        "# for mediapipe hands detection setup,mandatory\n",
        "mpHands = mp.solutions.hands\n",
        "hands = mpHands.Hands(max_num_hands=1)\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "\n",
        "pTime = 0\n",
        "cTime = 0\n",
        "\n",
        "ges = -1\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# drone.takeoff()\n",
        "# time.sleep(5)\n",
        "\n",
        "# imgTemp=drone.get_frame_read()\n",
        "\n",
        "# creating a thread to run the fucntion\n",
        "show_movement_thread=Thread(target=show_movement,daemon=True)\n",
        "show_movement_thread.start()\n",
        "\n",
        "while True:\n",
        "\n",
        "    success, img = cap.read()\n",
        "    # img = imgTemp.frame\n",
        "    img = cv2.flip(img, 1)\n",
        "    # img = cv2.resize(img, (360, 240))\n",
        "    # have to convert our image to rgb for detection\n",
        "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    results = hands.process(imgRGB)\n",
        "\n",
        "    if results.multi_hand_landmarks:\n",
        "        for handLms in results.multi_hand_landmarks:\n",
        "            data = np.array([])\n",
        "            for id, lm in enumerate(handLms.landmark):\n",
        "                # print(id, lm)\n",
        "                h, w, c = img.shape\n",
        "                # data = np.append(data, round(int(lm.x*w), 3))\n",
        "                # data = np.append(data, round(int(lm.y*h), 3))\n",
        "                data = np.append(data, (lm.x*w))\n",
        "                data = np.append(data, (lm.y*h))\n",
        "\n",
        "            data1=data\n",
        "            data1=data1.reshape(1,42)\n",
        "            data = torch.from_numpy(data).type(torch.float).to(device)\n",
        "            data=data.unsqueeze(dim=0)\n",
        "            ges = detectGes(data,data[0][0].clone(),data[0][1].clone())\n",
        "            # print(\"a\\n\")\n",
        "            # preprocess(data1)\n",
        "            # print(data,data1)\n",
        "            mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS)\n",
        "            \n",
        "    with lock:\n",
        "        if (ges == 0):\n",
        "            cv2.putText(img, \"FORWARD\", (10, 170),\n",
        "                    cv2.FONT_HERSHEY_PLAIN, 3, (255,0,0), 3)\n",
        "            forward_backward_vel=15\n",
        "            up_down_vel=0\n",
        "            left_right_vel=0\n",
        "            gesture_event.set()\n",
        "\n",
        "        elif (ges == 1):\n",
        "            cv2.putText(img, \"STOP\", (10, 170),\n",
        "                    cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 255), 3)\n",
        "            up_down_vel=0\n",
        "            left_right_vel=0\n",
        "            forward_backward_vel=0\n",
        "            gesture_event.set()\n",
        "\n",
        "        elif (ges == 2):\n",
        "            cv2.putText(img, \"UP\", (10, 170),\n",
        "                    cv2.FONT_HERSHEY_PLAIN, 3, (255,0,0), 3)\n",
        "            up_down_vel=-15\n",
        "            left_right_vel=0\n",
        "            forward_backward_vel=0\n",
        "            gesture_event.set()\n",
        "\n",
        "        elif (ges == 3):\n",
        "            cv2.putText(img, \"LAND\", (10, 170),\n",
        "                    cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 255), 3)\n",
        "            up_down_vel=0\n",
        "            left_right_vel=0\n",
        "            forward_backward_vel=0\n",
        "            land=True\n",
        "            gesture_event.set()\n",
        "\n",
        "        elif (ges == 4):\n",
        "            cv2.putText(img, \"DOWN\", (10, 170),\n",
        "                    cv2.FONT_HERSHEY_PLAIN, 3, (255,0,0), 3)\n",
        "            up_down_vel=15\n",
        "            left_right_vel=0\n",
        "            forward_backward_vel=0\n",
        "            gesture_event.set()\n",
        "\n",
        "        elif (ges == 5):\n",
        "            cv2.putText(img, \"BACK\", (10, 170),\n",
        "                    cv2.FONT_HERSHEY_PLAIN, 3, (255,0,0), 3)\n",
        "            forward_backward_vel=-15\n",
        "            left_right_vel=0\n",
        "            up_down_vel=0\n",
        "            gesture_event.set()\n",
        "\n",
        "        elif (ges == 6):\n",
        "            cv2.putText(img, \"LEFT\", (10, 170),\n",
        "                    cv2.FONT_HERSHEY_PLAIN, 3, (255,0,0), 3)\n",
        "            left_right_vel=-15\n",
        "            forward_backward_vel=0\n",
        "            up_down_vel=0\n",
        "            gesture_event.set()\n",
        "\n",
        "        elif (ges == 7):\n",
        "            cv2.putText(img, \"RIGHT\", (10, 170),\n",
        "                    cv2.FONT_HERSHEY_PLAIN, 3, (255,0,0), 3)\n",
        "            left_right_vel=15\n",
        "            forward_backward_vel=0\n",
        "            up_down_vel=0\n",
        "            gesture_event.set()\n",
        "        else:\n",
        "            cv2.putText(img,\" \",(10,170),cv2.FONT_HERSHEY_PLAIN,3,(0,255,0),3)\n",
        "\n",
        "    cTime = time.time()\n",
        "    fps = 1/(cTime-pTime)\n",
        "    pTime = cTime\n",
        "    # fps = 0\n",
        "    cv2.putText(img, str(int(fps)), (10, 70),\n",
        "                cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 0), 3)\n",
        "\n",
        "    cv2.imshow('Image', img)\n",
        "    key = cv2.waitKey(1) & 0xFF\n",
        "    if key == ord('q') and land:\n",
        "        cv2.destroyWindow('Image')\n",
        "        with lock:\n",
        "            left_right_vel=0\n",
        "            forward_backward_vel=0\n",
        "            up_down_vel=0\n",
        "            land=True\n",
        "            \n",
        "        cap.release()\n",
        "        # time.sleep(1)\n",
        "        # drone.streamoff()\n",
        "        break\n",
        "    # time.sleep(5)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "torch_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "e8d4d6c6035f59c3e5f3276bf06a6a08fd2ac903d3ffc891313661fec86d0e12"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
